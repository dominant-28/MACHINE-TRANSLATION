{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for start and end\n",
    "SOS_token=0\n",
    "EOS_token=1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2\n",
    "    \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1  \n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The reason for the unicodeToascii function is to convert Unicode strings to plain ASCII by removing special characters, accents, and diacritical marks (like é, ü, ñ, etc.).\n",
    "def unicodeToascii(s):\n",
    "    return ''.join(\n",
    "        c for c in  unicodedata.normalize('NFD',s)\n",
    "        if unicodedata.category(c)!='Mn'\n",
    "    )\n",
    "def normalizeString(s):\n",
    "    s=unicodeToascii(s.lower().strip())\n",
    "    s=re.sub(r\"([.!?])\",r\" \\1\",s) #Adds a space before each punctuation mark.\n",
    "    s=re.sub(r\"[^a-zA-z!?]+\",r\" \", s)#Removes any character that is not:A-Z a-z . ! ? replace with \" \"\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readlines(lang1, lang2, reverse=False):\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n') #split the text into the lines\n",
    "\n",
    "    pairs=[[normalizeString(s) for s in l.split('\\t')] for l in lines]   #normalize and clean the sentences for traning \n",
    "\n",
    "    if reverse:\n",
    "        pairs=[list(reversed(p)) for p in pairs]\n",
    "        input_lang=Lang(lang2)\n",
    "        output_lang=Lang(lang1)\n",
    "    else:\n",
    "        input_lang=Lang(lang1)\n",
    "        output_lang=Lang(lang2)   \n",
    "    return input_lang,output_lang,pairs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "#Complex sentences or rare structures may introduce noise, making it harder for the model to generalize effectively.\n",
    "#Lowers the computational cost of training a model.By focusing on the simple \n",
    "#and  well-aligned sentences ensures the model learns clean and accurate mappings.\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1,lang2 ,reverse=False):\n",
    "    input_lang,output_lang, pairs=readlines(lang1,lang2, reverse)\n",
    "    pairs = filterPairs(pairs)\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)    \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,dropout_p=0.1):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.hidden_size=hidden_size\n",
    "\n",
    "        self.embedding=nn.Embedding(input_size,hidden_size)\n",
    "        self.gru =nn.GRU(hidden_size,hidden_size,batch_first=True)\n",
    "        self.dropout=nn.Dropout(dropout_p)\n",
    "    def forward(self,input): \n",
    "        embedded=self.dropout(self.embedding(input))\n",
    "        output,hidden=self.gru(embedded)\n",
    "        return output,hidden   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,hidden_size,output_size):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.embedding= nn.Embedding(output_size, hidden_size)\n",
    "        self.gru=nn.GRU(hidden_size,hidden_size,batch_first=True)\n",
    "        self.out=nn.Linear(hidden_size,output_size)\n",
    "    def forward(self,endcoder_outputs,encoder_hidden,target_tensor=None):\n",
    "        batch_size=endcoder_outputs.size(0)\n",
    "        #Starting input is initialize as zeros\n",
    "        decoder_input=torch.empty(batch_size,1,dtype=torch.long,device=device).fill_(SOS_token)\n",
    "       #encoder output initialize the decoder starting hidden state  \n",
    "        decoder_hidden=encoder_hidden\n",
    "        decoder_outputs=[]\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output,decoder_hidden=self.forward_step(decoder_input,decoder_hidden)\n",
    "           #output contains the the logit for the every timestep of vocab size and which ever having large probability that word's embedding is send to the next timestep \n",
    "            decoder_outputs.append(decoder_output)\n",
    "            if(target_tensor is not None): #teacher forcing\n",
    "                decoder_input=target_tensor[:,i].unsqueeze(1)\n",
    "            else:\n",
    "\n",
    "                _,topi=decoder_output.topk(1)#select the most preferable token for the next step input\n",
    "          \n",
    "                decoder_input=topi.sequeeze(-1).detach()\n",
    "        #Combines the logits from all time steps into a single tensor of shape (batch_size, MAX_LENGTH, vocab_size).\n",
    "        decoder_outputs=torch.cat(decoder_outputs,dim=1)\n",
    "        #Converts logits into log-probabilities for the vocabulary. This is useful for training with negative log-likelihood loss.\n",
    "        decoder_outputs=F.log_softmax(decoder_outputs,dim=-1)\n",
    "        return decoder_outputs,decoder_hidden,None     \n",
    "    def forward_step(self,input,hidden):\n",
    "        output =self.embedding(input)\n",
    "        output=F.relu(output)\n",
    "        output,hidden=self.gru(output,hidden)\n",
    "        output=self.out(output)\n",
    "        return output,hidden          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Imagine a stage performance where multiple actors (input tokens) are acting at once. The decoder (query) represents the director who decides which actor to focus on.\n",
    "\n",
    "# Query: The director's current instructions (what's needed right now).\n",
    "# Keys: The actors' performances (encoder outputs).\n",
    "# Neural Network (Bahdanau Attention): The spotlight operator who decides, based on the director's instructions, which actor should be\n",
    "# highlighted. The weights determine how much focus each actor gets.\n",
    "class BahdanauAttention(nn.Module):\n",
    "  #Instead, it transforms them separately (using Wa and Ua) and then combines them (via addition) before applying tanh\n",
    "  #Let the network learn distinct transformations for the query and keys before combining them.  \n",
    "  #Bahdanau’s method focuses on the element-wise interaction (via addition) of the query and keys,\n",
    "  #as this preserves more individual information about each. Concatenation tends to mix the representations more, which may lose some structure but can still work depending on the task.\n",
    "\n",
    "\n",
    "    def __init__(self,hidden_size):\n",
    "        super(BahdanauAttention,self).__init__()\n",
    "        self.Wa =nn.Linear(hidden_size,hidden_size)\n",
    "        self.Ua=nn.Linear(hidden_size,hidden_size)\n",
    "        self.Va=nn.Linear(hidden_size,1)\n",
    "    def forward(self,query ,keys):   \n",
    "        scores=self.Va(torch.tanh(self.Wa(query)+self.Ua(keys)))\n",
    "        scores =scores.squeeze(2).unsqueeze(1)#squeeze :remove the dimension at specific pos of dim=1,if not specified it will Removes dimensions of size 1 from a tensor\n",
    "\n",
    "\n",
    "        weights=F.softmax(scores,dim=-1)#across the squence length\n",
    "        context =torch.bmm(weights,keys)#(batch matrix multiplication)The result is a single context vector for each query, summarizing the encoder information weighted by the attention scores.\n",
    "        return context,weights \n",
    "    \n",
    "\n",
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(self,hidden_size,output_size,dropout_p=0.1):\n",
    "        super(AttnDecoder,self).__init__()\n",
    "        self.embedding=nn.Embedding(output_size,hidden_size)\n",
    "        self.attention =BahdanauAttention(hidden_size)\n",
    "        self.gru =nn.GRU(2*hidden_size,hidden_size,batch_first=True)\n",
    "        self.out=nn.Linear(hidden_size,output_size)\n",
    "        self.dropout =nn.Dropout(dropout_p)\n",
    "    def forward(self,encoder_outputs,encoder_hidden,target_tensor=None):\n",
    "         batch_size=encoder_outputs.size(0)\n",
    "         decoder_input=torch.empty(batch_size,1,dtype=torch.long,device=device).fill_(SOS_token)\n",
    "         decoder_hidden=encoder_hidden \n",
    "         decoder_outputs=[]\n",
    "         attentions=[]\n",
    "\n",
    "         for i in range(MAX_LENGTH):\n",
    "             decoder_output,decoder_hidden,attn_weights=self.forward_step(decoder_input,decoder_hidden,encoder_outputs)\n",
    "             decoder_outputs.append(decoder_output)\n",
    "             attentions.append(attn_weights)\n",
    "\n",
    "\n",
    "             if target_tensor is not None:\n",
    "                 decoder_input=target_tensor[:,i].unsqueeze(1)\n",
    "             else:\n",
    "                 _,topi=decoder_output.topk(1)\n",
    "                 decoder_input=topi.squeeze(-1).detach()\n",
    "\n",
    "\n",
    "\n",
    "         decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "         decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "         attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "         return decoder_outputs, decoder_hidden, attentions    \n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair, input_lang, output_lang):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return input_lang, output_lang, train_dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    # Create the figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot the points\n",
    "    ax.plot(points)\n",
    "\n",
    "    # Optional: Customize labels and title\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(\"Training Loss over Epochs\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001, plot_every=100):\n",
    "    plot_losses = []\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    # Define optimizers and loss function\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # Initialize tqdm progress bar for the epoch\n",
    "        epoch_loss = 0\n",
    "        with tqdm(train_dataloader, desc=f\"Epoch {epoch}/{n_epochs}\", unit=\"batch\") as progress_bar:\n",
    "            for data in progress_bar:\n",
    "                input_tensor, target_tensor = data\n",
    "                encoder_optimizer.zero_grad()\n",
    "                decoder_optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "                decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "                # Calculate loss\n",
    "                loss = criterion(\n",
    "                    decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "                    target_tensor.view(-1)\n",
    "                )\n",
    "                loss.backward()\n",
    "\n",
    "                # Update weights\n",
    "                encoder_optimizer.step()\n",
    "                decoder_optimizer.step()\n",
    "\n",
    "                # Accumulate batch loss\n",
    "                batch_loss = loss.item()\n",
    "                epoch_loss += batch_loss\n",
    "\n",
    "                # Update progress bar with the current batch loss\n",
    "                progress_bar.set_postfix(loss=batch_loss)\n",
    "\n",
    "        # Calculate average loss for the epoch\n",
    "        avg_loss = epoch_loss / len(train_dataloader)\n",
    "        plot_loss_total += avg_loss\n",
    "\n",
    "        # Update plot losses periodically\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    # Display the loss plot at the end\n",
    "    showPlot(plot_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder,pairs,input_lang,output_lang ,decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('Input:', pair[0])\n",
    "        print('Target: ', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('Output:', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "encoder = Encoder(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoder(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, 100, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "evaluateRandomly(encoder,pairs ,input_lang,output_lang,decoder, n=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
